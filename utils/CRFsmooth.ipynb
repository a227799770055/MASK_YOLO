{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from genericpath import isdir\n",
    "import sys\n",
    "sys.path.append('/home/insign/Doc/insign/Mask_yolo')\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np \n",
    "from model.od.data.datasets import letterbox\n",
    "from typing import Any\n",
    "from model.backbone_YOLO import *\n",
    "from model.head_RCNN import *\n",
    "from model.groundtrue_import import *\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import pydensecrf.densecrf as dcrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgPath = '/home/insign/Doc/insign/Mask_yolo/config/yolocfg.yaml'\n",
    "roimodelPath = '/home/insign/Doc/insign/Mask_yolo/run/0824_fcnhead_size640/best.pt'\n",
    "\n",
    "#   Loading config file\n",
    "with open(cfgPath, 'r') as f:\n",
    "        cfg = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "#   Setting device\n",
    "device = 'cpu'\n",
    "\n",
    "#   Model yolo_backbone loading\n",
    "yolo = model_manipulate(cfg['model']['weight']).eval().to(device)\n",
    "\n",
    "#   Model roi_head loading\n",
    "mask_head = torch.load(roimodelPath).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = '/home/insign/Doc/insign/Mask_yolo/Polyp/Validate/44.jpg'\n",
    "\n",
    "def image_loading(img_path):\n",
    "    image = cv2.imread(str(img_path))\n",
    "    img_h, img_w = image.shape[0], image.shape[1]\n",
    "    image = letterbox(image, new_shape=480)[0]\n",
    "    im0s = deepcopy(image)\n",
    "    image = image[:, :, ::-1].transpose(2, 0, 1)\n",
    "    image = np.ascontiguousarray(image)\n",
    "    image = torch.from_numpy(image).unsqueeze(0).to(device)\n",
    "    image = image.float()\n",
    "    image /= 255.0\n",
    "    return image, im0s, img_h, img_w\n",
    "\n",
    "image, im0s, img_h, img_w = image_loading(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_detection(image, yolo, mask_head, cfg):\n",
    "    #   Predict bounding box\n",
    "    pred = yolo(image)\n",
    "    rois = non_max_suppression(pred['rois'][0],cfg['nms']['conf_thres'], cfg['nms']['iou_thres'], classes= cfg['nms']['classes'],agnostic=cfg['nms']['agnostic_nms'])\n",
    "    boxes = rois[0][:,:4]#  rois\n",
    "    if len(boxes) == 0:\n",
    "        return [], []\n",
    "    feature_map = featuremapPack(pred['feature_map']) #   extract feature map and boxes\n",
    "    cv2.rectangle(im0s, (int(boxes[0][0]), int(boxes[0][1])), (int(boxes[0][2]), int(boxes[0][3])), (0, 255, 0), 2)\n",
    "\n",
    "    #   Resize to bounding box\n",
    "    h = int(boxes[0][2] - boxes[0][0])\n",
    "    w = int(boxes[0][3] - boxes[0][1])\n",
    "    resize_to_bbs = transforms.Compose([transforms.Resize((w, h))])\n",
    "    \n",
    "    #   Predict mask\n",
    "    mask_logits = mask_head(feature_map, boxes)\n",
    "    mask = mask_logits.detach().cpu().numpy()\n",
    "    mask_logits = resize_to_bbs(mask_logits)\n",
    "    mask_logits = mask_logits.detach().cpu().numpy()\n",
    "    mask_logits = mask_logits[0][0]>0.5\n",
    "    mask_logits.dtype = 'uint8'\n",
    "    mask_logits = mask_logits*255\n",
    "    mask_logits = cv2.cvtColor(mask_logits, cv2.COLOR_GRAY2RGB)\n",
    "    return boxes, mask_logits, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   prediction\n",
    "boxes, mask_logits, mask = model_detection(image, yolo, mask_head, cfg)\n",
    "\n",
    "mask = mask[0]\n",
    "mask = mask.reshape((1,-1))\n",
    "\n",
    "d = dcrf.DenseCRF2D(126, 126, 1)\n",
    "d.addPairwiseGaussian(sxy=(10,10), compat=3, kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "d.setUnaryEnergy(mask)\n",
    "\n",
    "mask = mask.reshape((126,126))\n",
    "mask = mask>0.5\n",
    "mask.dtype = 'uint8'\n",
    "mask = mask*255\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "cv2.imwrite('mask.jpg', mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
